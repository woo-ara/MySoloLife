{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkBixesxWm+47zLcUxyAZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woo-ara/MySoloLife/blob/master/MNIST1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUisxOtOLid7"
      },
      "source": [
        "MNIST 데이터를 사용하여 심층 신경망을 구현하고, 과적합을 방지하기 위한 dropout과 batch normalization을 적용하여 결과를 분석하여 파이썬 코드와 실행결과를 정리한 보고서를 학번-이름.pdf로 변환하여 기한 내에 이클래스에 제출하세요.\n",
        " \n",
        "\n",
        "1. 데이터는 MNIST를 사용합니다.\n",
        "\n",
        "2. 심층신경망의 입력층, 은닉층 3개(첫번째, 두번째, 세번째 은닉층 노드 개수 각각 256개, 256개, 256개), 출력층으로 되어 있는 모델을 생성하고 그밖의 사항들은 자유롭게 지정하면 됩니다.\n",
        "\n",
        "3. 최적화 방법은 Gradient Descent Optimization 을 사용합니다.\n",
        "\n",
        "4. 과적합 방지를 위해 dropout의 수치를 변경하면서 성능을 분석합니다.\n",
        "\n",
        "5. 과적합 방지를 위해 batch normalization을 수행하여 성능을 분석합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDclPRGxLmik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ecbfc0-5b2a-4e98-e89b-2fa0a7a86370"
      },
      "source": [
        "#python 버전 확인\n",
        "!python --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsVj02-P5K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e57ef01-94a4-4d07-bde7-e41dde9e99dc"
      },
      "source": [
        "#tensorflow 버전 확인\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1pOVkvLP7fF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9c760fa-3024-4ab1-f5a2-1c4923672433"
      },
      "source": [
        "# 2.x 버전일 경우 현재 tenserflow 제거\n",
        "!pip uninstall tensorflow\n",
        "\n",
        "# 1.15 버전으로 tensorflow 설치\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.7.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.13.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 16.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 50.7 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.42.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=8f1de3814ed227b9d9684670b787b10465f04229caf8681654196abc04e98866\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdD8NhHCP9oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef2f9a29-961c-4691-f630-95e32fed467d"
      },
      "source": [
        "#TensorFlow 및 MNIST 데이터셋 임포트\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터를 내려받은 후 레이블을 one-hot encoding 방식으로 읽어들임\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-167044623bee>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36PG8vQMbdyU"
      },
      "source": [
        "#신경망 모델 구성:입력, 출력 정의\n",
        "#X와 Y 텐서의 첫번째 차원:None\n",
        "#한 번에 학습시킬 MNIST 이미지의 개수 지정:배치 크기 지정\n",
        "X = tf.placeholder(tf.float32, [None, 784]) #영상의 크기가 28x28(=784)\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6VTW0iRbfpk",
        "outputId": "cd62f285-7661-4f14-bd68-8dcf845d3bce"
      },
      "source": [
        "#3개의 은닉층이 다음처럼 구성된 신경망 생성\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))  #표준편차 0.01\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, 0.8)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, 0.8)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L3 = tf.nn.relu(tf.matmul(L2, W3))\n",
        "L3 = tf.nn.dropout(L3, 0.8)\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-95c6dfc3b5ca>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHVYJIUpcOHg"
      },
      "source": [
        "#손실 함수와 최적화 함수 적용\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2\n",
        "                      (logits=model, labels=Y))\n",
        "\n",
        "#최적화 방법은 Gradient Descent Optimization\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "#optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdL__XRScp5E",
        "outputId": "22df4dc6-2b14-47ec-a99a-4b0f4407ff82"
      },
      "source": [
        "#결과 확인\n",
        "#신경망 모델 초기화 및 세션 시작\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(15):\n",
        "  total_cost = 0\n",
        "\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "    _, cost_val = sess.run([optimizer, cost], \n",
        "                           feed_dict={X: batch_xs, Y: batch_ys})\n",
        "    total_cost += cost_val\n",
        "  \n",
        "  print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost = ', '{:.3f}'.format\n",
        "        (total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "#예측값과 실제값 비교\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "\n",
        "#정확도 계산 후 출력\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "                                         "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 Avg. cost =  2.302\n",
            "Epoch: 0002 Avg. cost =  2.293\n",
            "Epoch: 0003 Avg. cost =  1.340\n",
            "Epoch: 0004 Avg. cost =  0.432\n",
            "Epoch: 0005 Avg. cost =  0.259\n",
            "Epoch: 0006 Avg. cost =  0.192\n",
            "Epoch: 0007 Avg. cost =  0.155\n",
            "Epoch: 0008 Avg. cost =  0.131\n",
            "Epoch: 0009 Avg. cost =  0.116\n",
            "Epoch: 0010 Avg. cost =  0.099\n",
            "Epoch: 0011 Avg. cost =  0.089\n",
            "Epoch: 0012 Avg. cost =  0.080\n",
            "Epoch: 0013 Avg. cost =  0.072\n",
            "Epoch: 0014 Avg. cost =  0.068\n",
            "Epoch: 0015 Avg. cost =  0.059\n",
            "최적화 완료!\n",
            "정확도:  0.9683\n"
          ]
        }
      ]
    }
  ]
}