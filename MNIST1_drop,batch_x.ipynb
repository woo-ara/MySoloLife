{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST1_drop,batch x",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPQoQgG0nLVWKPlR75nJkD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woo-ara/MySoloLife/blob/master/MNIST1_drop%2Cbatch_x.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUisxOtOLid7"
      },
      "source": [
        "MNIST 데이터를 사용하여 심층 신경망을 구현하고, 과적합을 방지하기 위한 dropout과 batch normalization을 적용하여 결과를 분석하여 파이썬 코드와 실행결과를 정리한 보고서를 학번-이름.pdf로 변환하여 기한 내에 이클래스에 제출하세요.\n",
        " \n",
        "\n",
        "1. 데이터는 MNIST를 사용합니다.\n",
        "\n",
        "2. 심층신경망의 입력층, 은닉층 3개(첫번째, 두번째, 세번째 은닉층 노드 개수 각각 256개, 256개, 256개), 출력층으로 되어 있는 모델을 생성하고 그밖의 사항들은 자유롭게 지정하면 됩니다.\n",
        "\n",
        "3. 최적화 방법은 Gradient Descent Optimization 을 사용합니다.\n",
        "\n",
        "4. 과적합 방지를 위해 droupout의 수치를 변경하면서 성능을 분석합니다.\n",
        "\n",
        "5. 과적합 방지를 위해 batch normalization을 수행하여 성능을 분석합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDclPRGxLmik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bf34c6-2cc9-48d2-c6da-a6c39374dff3"
      },
      "source": [
        "#python 버전 확인\n",
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsVj02-P5K6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc0dcc4-1473-4d39-8339-81cf1336656a"
      },
      "source": [
        "#tensorflow 버전 확인\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1pOVkvLP7fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb82f75-3670-43ba-c89d-79ee7d57a7d9"
      },
      "source": [
        "# 2.x 버전일 경우 현재 tenserflow 제거\n",
        "!pip uninstall tensorflow\n",
        "\n",
        "# 1.15 버전으로 tensorflow 설치\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 1.15.0\n",
            "Uninstalling tensorflow-1.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-1.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0\n",
            "Collecting tensorflow==1.15\n",
            "  Using cached tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.42.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.13.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Installing collected packages: tensorflow\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorflow-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdD8NhHCP9oS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ceed140-f667-40d7-fe83-54825830f9fe"
      },
      "source": [
        "#TensorFlow 및 MNIST 데이터셋 임포트\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터를 내려받은 후 레이블을 one-hot encoding 방식으로 읽어들임\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-167044623bee>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36PG8vQMbdyU"
      },
      "source": [
        "#신경망 모델 구성:입력, 출력 정의\n",
        "#X와 Y 텐서의 첫번째 차원:None\n",
        "#한 번에 학습시킬 MNIST 이미지의 개수 지정:배치 크기 지정\n",
        "X = tf.placeholder(tf.float32, [None, 784]) #영상의 크기가 28x28(=784)\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6VTW0iRbfpk"
      },
      "source": [
        "#3개의 은닉층이 다음처럼 구성된 신경망 생성\n",
        "#784(입력, 특징 개수) -> 256(첫 번째 은닉층 뉴런 개수) -> 256(두 번째 은닉층 뉴런 개수) -> 256(세 번째 은닉층 뉴런 개수)-> 10(결괏값 0~9 분류 개수)\n",
        "W1 = tf.Variable(tf.random_normal([784,256],stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L3 = tf.nn.relu(tf.matmul(L2, W3))\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHVYJIUpcOHg"
      },
      "source": [
        "#손실 함수와 최적화 함수 적용\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2\n",
        "                      (logits=model, labels=Y))\n",
        "\n",
        "#최적화 방법은 Gradient Descent Optimization\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "#optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdL__XRScp5E",
        "outputId": "8126c098-5499-4bf6-f0eb-e639c1b84b6d"
      },
      "source": [
        "#결과 확인\n",
        "#신경망 모델 초기화 및 세션 시작\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(15):\n",
        "  total_cost = 0\n",
        "\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "\n",
        "    _, cost_val = sess.run([optimizer, cost], \n",
        "                           feed_dict={X: batch_xs, Y: batch_ys})\n",
        "    total_cost += cost_val\n",
        "  \n",
        "  print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost = ', '{:.3f}'.format\n",
        "        (total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "                                         "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 Avg. cost =  2.303\n",
            "Epoch: 0002 Avg. cost =  2.303\n",
            "Epoch: 0003 Avg. cost =  2.302\n",
            "Epoch: 0004 Avg. cost =  2.302\n",
            "Epoch: 0005 Avg. cost =  2.302\n",
            "Epoch: 0006 Avg. cost =  2.302\n",
            "Epoch: 0007 Avg. cost =  2.302\n",
            "Epoch: 0008 Avg. cost =  2.302\n",
            "Epoch: 0009 Avg. cost =  2.302\n",
            "Epoch: 0010 Avg. cost =  2.302\n",
            "Epoch: 0011 Avg. cost =  2.302\n",
            "Epoch: 0012 Avg. cost =  2.301\n",
            "Epoch: 0013 Avg. cost =  2.301\n",
            "Epoch: 0014 Avg. cost =  2.300\n",
            "Epoch: 0015 Avg. cost =  2.297\n",
            "최적화 완료!\n"
          ]
        }
      ]
    }
  ]
}